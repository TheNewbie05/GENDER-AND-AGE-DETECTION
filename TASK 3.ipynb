{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2d480e4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import urllib.request\n",
    "\n",
    "# Create directories to store data\n",
    "os.makedirs('data/images', exist_ok=True)\n",
    "\n",
    "# Download dataset (example: CelebA dataset)\n",
    "url = 'https://s3.amazonaws.com/fast-ai-imageclas/imagenette2-160.tgz'\n",
    "urllib.request.urlretrieve(url, 'data/images/imagenette2-160.tgz')\n",
    "\n",
    "# Extract dataset\n",
    "import tarfile\n",
    "with tarfile.open('data/images/imagenette2-160.tgz', 'r:gz') as tar: \n",
    "    tar.extractall('data/images/')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69d8b2fc",
   "metadata": {},
   "source": [
    "IMAGE PREPROCESSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "28966109",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "def preprocess_image(image_path, target_size=(224, 224)):\n",
    "    image = Image.open(image_path)\n",
    "    image = image.resize(target_size)\n",
    "    image = np.array(image) / 255.0  # Normalize pixel values\n",
    "    return image\n",
    "\n",
    "image_path = 'data/images/imagenette2-160/val/n01440764/ILSVRC2012_val_00009111.JPEG'\n",
    "preprocessed_image = preprocess_image(image_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d28e50a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Mishra\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n",
      "WARNING:tensorflow:From C:\\Users\\Mishra\\anaconda3\\Lib\\site-packages\\keras\\src\\backend.py:1398: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Mishra\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\normalization\\batch_normalization.py:979: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
      "\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet_v2/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_224_no_top.h5\n",
      "9406464/9406464 [==============================] - 2s 0us/step\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "base_model = MobileNetV2(weights='imagenet', include_top=False)\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "predictions = Dense(2, activation='softmax')(x)\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "# Freeze pre-trained layers\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c3373905",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\visha\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n",
      "WARNING:tensorflow:From c:\\Users\\visha\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\backend.py:1398: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\visha\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\normalization\\batch_normalization.py:979: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
      "\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet_v2/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_224_no_top.h5\n",
      "9406464/9406464 [==============================] - 3s 0us/step\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "# Assuming there are 10 classes in your dataset\n",
    "num_classes = 10\n",
    "\n",
    "base_model = MobileNetV2(weights='imagenet', include_top=False)\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "predictions = Dense(num_classes, activation='softmax')(x)  # Adjust number of units here\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "# Freeze pre-trained layers\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9dbdfabc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 9469 images belonging to 10 classes.\n",
      "WARNING:tensorflow:From c:\\Users\\visha\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:From c:\\Users\\visha\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\visha\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "296/296 [==============================] - 200s 666ms/step - loss: 0.4180 - accuracy: 0.8808\n",
      "Epoch 2/10\n",
      "296/296 [==============================] - 145s 490ms/step - loss: 0.1811 - accuracy: 0.9445\n",
      "Epoch 3/10\n",
      "296/296 [==============================] - 144s 486ms/step - loss: 0.1603 - accuracy: 0.9464\n",
      "Epoch 4/10\n",
      "296/296 [==============================] - 143s 482ms/step - loss: 0.1314 - accuracy: 0.9580\n",
      "Epoch 5/10\n",
      "296/296 [==============================] - 141s 477ms/step - loss: 0.1261 - accuracy: 0.9590\n",
      "Epoch 6/10\n",
      "296/296 [==============================] - 145s 488ms/step - loss: 0.1161 - accuracy: 0.9608\n",
      "Epoch 7/10\n",
      "296/296 [==============================] - 140s 474ms/step - loss: 0.1194 - accuracy: 0.9610\n",
      "Epoch 8/10\n",
      "296/296 [==============================] - 141s 476ms/step - loss: 0.1098 - accuracy: 0.9636\n",
      "Epoch 9/10\n",
      "296/296 [==============================] - 138s 465ms/step - loss: 0.1073 - accuracy: 0.9632\n",
      "Epoch 10/10\n",
      "296/296 [==============================] - 131s 443ms/step - loss: 0.1047 - accuracy: 0.9653\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x24f091f73d0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    'data/images/imagenette2-160/train',\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.fit(train_generator, epochs=10, steps_per_epoch=len(train_generator))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "45387d9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3925 images belonging to 10 classes.\n",
      "123/123 [==============================] - 56s 449ms/step - loss: 0.0970 - accuracy: 0.9687\n",
      "Validation Accuracy: 0.968662440776825\n"
     ]
    }
   ],
   "source": [
    "validation_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "validation_generator = validation_datagen.flow_from_directory(\n",
    "    'data/images/imagenette2-160/val',\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "loss, accuracy = model.evaluate(validation_generator)\n",
    "print(f'Validation Accuracy: {accuracy}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "324e389e",
   "metadata": {},
   "source": [
    "MODEL COMPILATION\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1267d5e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "# Define model architecture with separate output layers for gender and age\n",
    "base_model = MobileNetV2(weights='imagenet', include_top=False)\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "gender_predictions = Dense(2, activation='softmax', name='gender_predictions')(x)  # Output layer for gender\n",
    "age_predictions = Dense(5, activation='softmax', name='age_predictions')(x)  # Output layer for age\n",
    "model = Model(inputs=base_model.input, outputs=[gender_predictions, age_predictions])\n",
    "\n",
    "# Freeze pre-trained layers\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Compile the model with appropriate loss functions for gender and age\n",
    "model.compile(optimizer='adam',\n",
    "              loss={'gender_predictions': 'categorical_crossentropy', 'age_predictions': 'categorical_crossentropy'},\n",
    "              metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db698f38",
   "metadata": {},
   "source": [
    "GENDER PREDICTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4653cf53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 40ms/step\n",
      "Predicted Gender: Male\n",
      "Predicted Age: Adult\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing import image\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# Load and preprocess the image\n",
    "img_path = r'D:\\Int Project\\BASIC\\Gender-and-Age-Detection-master\\Gender-and-Age-Detection-master\\man2.jpg'  # Update with the path to your image\n",
    "img = image.load_img(img_path, target_size=(224, 224))\n",
    "img_array = image.img_to_array(img)\n",
    "img_array = np.expand_dims(img_array, axis=0)\n",
    "img_array /= 255.  # Normalization\n",
    "\n",
    "\n",
    "# Make predictions\n",
    "gender_predictions, age_predictions = model.predict(img_array)\n",
    "\n",
    "\n",
    "# Get predicted gender and age class indices\n",
    "predicted_gender_index = np.argmax(gender_predictions)\n",
    "predicted_age_index = np.argmax(age_predictions)\n",
    "\n",
    "\n",
    "# Assuming you have dictionaries mapping class indices to class labels for gender and age\n",
    "gender_labels = {0: 'Female', 1: 'Male'}\n",
    "age_labels = {0: 'Senior', 1: 'Adult', 2: 'Young Adult', 3: 'Teenager', 4: 'Child'}\n",
    "\n",
    "\n",
    "# Get predicted gender and age labels\n",
    "predicted_gender_label = gender_labels.get(predicted_gender_index, \"Unknown Gender\")\n",
    "predicted_age_label = age_labels.get(predicted_age_index, \"Unknown Age\")\n",
    "\n",
    "\n",
    "# Print predicted gender and age\n",
    "print(\"Predicted Gender:\", predicted_gender_label)\n",
    "print(\"Predicted Age:\", predicted_age_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b0f92d5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
